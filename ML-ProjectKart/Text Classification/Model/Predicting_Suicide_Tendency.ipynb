{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Predicting_Suicide_Tendency.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZwdIAyx5sfy"
      },
      "source": [
        "Over the years, suicide has been one of the major causes of death worldwide, According to Wikipedia, Suicide resulted in 828,000 global deaths in 2015, an increase from 712,000 deaths in 1990. This makes suicide the 10th leading cause of death worldwide. There is also increasing evidence that the Internet and social media can influence suicide-related behaviour. Using Natural Language Processing, a field in Machine Learning, I built a very simple suicidal ideation classifier which predict whether a text is likely to be suicidal or not."
      ],
      "id": "EZwdIAyx5sfy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC5hxw6l8H9o"
      },
      "source": [
        "Sentiment analysis refers to identifying as well as classifying the sentiments that are expressed in the text source. Tweets are often useful in generating a vast amount of sentiment data upon analysis. These data are useful in understanding the opinion of the people about a variety of topics."
      ],
      "id": "IC5hxw6l8H9o"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a33fa948"
      },
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "a33fa948",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa26907b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "24100c38-4210-49bf-f069-1a692562a63a"
      },
      "source": [
        "# Get the data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/laxmimerit/twitter-suicidal-intention-dataset/master/twitter-suicidal_data.csv\")\n",
        "df.head()"
      ],
      "id": "fa26907b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  intention\n",
              "0  my life is meaningless i just want to end my l...          1\n",
              "1  muttering i wanna die to myself daily for a fe...          1\n",
              "2  work slave i really feel like my only purpose ...          1\n",
              "3  i did something on the 2 of october i overdose...          1\n",
              "4  i feel like no one cares i just want to die ma...          1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ce8f50b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fea7ac-24d6-4a08-d036-fe4fe235c50e"
      },
      "source": [
        "# Counting the data each label holds\n",
        "df['intention'].value_counts()"
      ],
      "id": "2ce8f50b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5121\n",
              "1    3998\n",
              "Name: intention, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb791fa6"
      },
      "source": [
        "<h3>Preprocessing</h3>"
      ],
      "id": "bb791fa6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8556dc4f"
      },
      "source": [
        "import re\n",
        "def clean_tweets(text):\n",
        "    text = re.sub('http\\S+\\s*', ' ', text) #Remove URls\n",
        "    text = re.sub(r'@[A-Za-z0-9]+','',text) #Removing @ mentions\n",
        "    text = re.sub(r'#','',text) #Removing the hashtag symbol\n",
        "    text = re.sub(r'RT[\\s]+','',text) #Removing RT\n",
        "    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text) #Remove repeating characters\n",
        "    \n",
        "    return text"
      ],
      "id": "8556dc4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "873f51d8"
      },
      "source": [
        "df['tweet'] = df['tweet'].apply(lambda x:clean_tweets(x))"
      ],
      "id": "873f51d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd1e05cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e748ae56-2eef-4b69-b648-ee43a6294d15"
      },
      "source": [
        "df.head()"
      ],
      "id": "dd1e05cf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  intention\n",
              "0  my life is meaningless i just want to end my l...          1\n",
              "1  muttering i wanna die to myself daily for a fe...          1\n",
              "2  work slave i really feel like my only purpose ...          1\n",
              "3  i did something on the 2 of october i overdose...          1\n",
              "4  i feel like no one cares i just want to die ma...          1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a43d17f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9667eacc-0674-4978-f7b4-44d0e325f7dd"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "#Taking top 20000 dictionary words into account\n",
        "#unigram, bigram, trigram ---> there is a single word, combination of 2 words, combination of 3 words\n",
        "#character analyzer ---> character by character tokenization\n",
        "text_clf_rf = Pipeline([('word_vectorizer', TfidfVectorizer(max_features = 20000, ngram_range=(1,3), analyzer='char')),\n",
        "                    ('clf', RandomForestClassifier())])\n",
        "\n",
        "text_clf_knn = Pipeline([('word_vectorizer', TfidfVectorizer(max_features = 20000, ngram_range=(1,3), analyzer='char')),\n",
        "                    ('clf', KNeighborsClassifier())])\n",
        "\n",
        "text_clf_lsvc = Pipeline([('word_vectorizer', TfidfVectorizer(max_features = 20000, ngram_range=(1,3), analyzer='char')),\n",
        "                    ('clf', LinearSVC())])\n",
        "\n",
        "print (\"Feature completed .....\")"
      ],
      "id": "a43d17f2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature completed .....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba45083d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a73414c-d8a2-4902-cb80-f3bcb1f887f1"
      },
      "source": [
        "# Splitting the dataset into training and testing data\n",
        "X_train,X_test,y_train,y_test = train_test_split(df['tweet'],df['intention'],random_state=0, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "id": "ba45083d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7295,)\n",
            "(1824,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6djbHxmr-bco"
      },
      "source": [
        "# Linear SVC"
      ],
      "id": "6djbHxmr-bco"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fe5a2f0"
      },
      "source": [
        "#Fitting the data to the model\n",
        "text_clf_lsvc.fit(X_train,y_train)\n",
        "prediction = text_clf_lsvc.predict(X_test)"
      ],
      "id": "7fe5a2f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d8f01cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329a22e6-872e-405b-df2f-a66c53c76ed9"
      },
      "source": [
        "print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (text_clf_lsvc, metrics.classification_report(y_test, prediction)))"
      ],
      "id": "1d8f01cd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Classification report for classifier Pipeline(memory=None,\n",
            "         steps=[('word_vectorizer',\n",
            "                 TfidfVectorizer(analyzer='char', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.float64'>,\n",
            "                                 encoding='utf-8', input='content',\n",
            "                                 lowercase=True, max_df=1.0, max_features=20000,\n",
            "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
            "                                 preprocessor=None, smooth_idf=True,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 sublinear_tf=False,\n",
            "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                 tokenizer=None, use_idf=True,\n",
            "                                 vocabulary=None)),\n",
            "                ('clf',\n",
            "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
            "                           fit_intercept=True, intercept_scaling=1,\n",
            "                           loss='squared_hinge', max_iter=1000,\n",
            "                           multi_class='ovr', penalty='l2', random_state=None,\n",
            "                           tol=0.0001, verbose=0))],\n",
            "         verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94      1060\n",
            "           1       0.91      0.92      0.91       764\n",
            "\n",
            "    accuracy                           0.93      1824\n",
            "   macro avg       0.92      0.93      0.93      1824\n",
            "weighted avg       0.93      0.93      0.93      1824\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3sVb_fQ-fZa"
      },
      "source": [
        "# Kneighbors Classifier"
      ],
      "id": "M3sVb_fQ-fZa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX2AuSVr-Utk"
      },
      "source": [
        "#Fitting the data to the model\n",
        "text_clf_knn.fit(X_train,y_train)\n",
        "prediction = text_clf_knn.predict(X_test)"
      ],
      "id": "AX2AuSVr-Utk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii12tWxx-oJq",
        "outputId": "067454b3-cc7c-4b7f-8974-6dcc1c8335b4"
      },
      "source": [
        "print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (text_clf_lsvc, metrics.classification_report(y_test, prediction)))"
      ],
      "id": "ii12tWxx-oJq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Classification report for classifier Pipeline(memory=None,\n",
            "         steps=[('word_vectorizer',\n",
            "                 TfidfVectorizer(analyzer='char', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.float64'>,\n",
            "                                 encoding='utf-8', input='content',\n",
            "                                 lowercase=True, max_df=1.0, max_features=20000,\n",
            "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
            "                                 preprocessor=None, smooth_idf=True,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 sublinear_tf=False,\n",
            "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                 tokenizer=None, use_idf=True,\n",
            "                                 vocabulary=None)),\n",
            "                ('clf',\n",
            "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
            "                           fit_intercept=True, intercept_scaling=1,\n",
            "                           loss='squared_hinge', max_iter=1000,\n",
            "                           multi_class='ovr', penalty='l2', random_state=None,\n",
            "                           tol=0.0001, verbose=0))],\n",
            "         verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.21      0.34      1060\n",
            "           1       0.48      1.00      0.64       764\n",
            "\n",
            "    accuracy                           0.54      1824\n",
            "   macro avg       0.74      0.60      0.49      1824\n",
            "weighted avg       0.78      0.54      0.47      1824\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmvdEZD6-uD-"
      },
      "source": [
        "# Random Forest Classifier"
      ],
      "id": "wmvdEZD6-uD-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BII2iGJh-yx8"
      },
      "source": [
        "#Fitting the data to the model\n",
        "text_clf_rf.fit(X_train,y_train)\n",
        "prediction = text_clf_rf.predict(X_test)"
      ],
      "id": "BII2iGJh-yx8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn-20Tni-8vH",
        "outputId": "f468a145-16e1-40a8-eef2-8e484a45ec4f"
      },
      "source": [
        "print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (text_clf_rf, metrics.classification_report(y_test, prediction)))"
      ],
      "id": "Kn-20Tni-8vH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Classification report for classifier Pipeline(memory=None,\n",
            "         steps=[('word_vectorizer',\n",
            "                 TfidfVectorizer(analyzer='char', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.float64'>,\n",
            "                                 encoding='utf-8', input='content',\n",
            "                                 lowercase=True, max_df=1.0, max_features=20000,\n",
            "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
            "                                 preprocessor=None, smooth_idf=True,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 sublinear_tf=False,\n",
            "                                 toke...\n",
            "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
            "                                        class_weight=None, criterion='gini',\n",
            "                                        max_depth=None, max_features='auto',\n",
            "                                        max_leaf_nodes=None, max_samples=None,\n",
            "                                        min_impurity_decrease=0.0,\n",
            "                                        min_impurity_split=None,\n",
            "                                        min_samples_leaf=1, min_samples_split=2,\n",
            "                                        min_weight_fraction_leaf=0.0,\n",
            "                                        n_estimators=100, n_jobs=None,\n",
            "                                        oob_score=False, random_state=None,\n",
            "                                        verbose=0, warm_start=False))],\n",
            "         verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1060\n",
            "           1       0.95      0.82      0.88       764\n",
            "\n",
            "    accuracy                           0.91      1824\n",
            "   macro avg       0.92      0.90      0.90      1824\n",
            "weighted avg       0.91      0.91      0.91      1824\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUqsKsGaHW_2"
      },
      "source": [
        "As you can see Linear SVC has higher accuracy than knn and Random Forest Classifier. Hence we decided to save our final model with linear SVC classifier."
      ],
      "id": "HUqsKsGaHW_2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc514cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b89ed81-7b34-4646-f0d8-e6d2ffcef725"
      },
      "source": [
        "test_ans = '''I don't feel like I can stand anymore stress in my life. \n",
        "                I want to end it for once and all.'''\n",
        "text_clf_lsvc.predict([test_ans])[0]"
      ],
      "id": "cc514cd7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df3e1c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98bf3c9-5ecb-4f0d-a10e-117f4eaaa038"
      },
      "source": [
        "test_ans_pos = '''I wish tremendous joy and good health to you and your family.'''\n",
        "text_clf_lsvc.predict([test_ans_pos])[0]"
      ],
      "id": "df3e1c72",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f457b3a"
      },
      "source": [
        "# Saving the state of working model so that it could be imported later in twitter sentiment analysis model\n",
        "import pickle"
      ],
      "id": "1f457b3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "518dd607"
      },
      "source": [
        "with open('suicide_tendency_model', 'wb') as to_write:\n",
        "    pickle.dump(text_clf_lsvc, to_write)"
      ],
      "id": "518dd607",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvi2dnOQIUdl"
      },
      "source": [
        "Thus the model helps in classifying suicidal texts with an accuracy of 93%"
      ],
      "id": "Lvi2dnOQIUdl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9e4f4c"
      },
      "source": [
        ""
      ],
      "id": "be9e4f4c",
      "execution_count": null,
      "outputs": []
    }
  ]
}
